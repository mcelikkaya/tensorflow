{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_mnist_board_summary.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE-NCgnB-jY9",
        "colab_type": "code",
        "outputId": "4175bb53-2f94-4073-db98-bf91a4996437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "\"\"\"\n",
        "I want to test if i can understand the quality of my model with tensorboard.\n",
        "For this experiment I will train same network for different epochs.\n",
        "I will see the accuracy going up and checck tensorflow for different accuracies.\n",
        "Infact this does not mean the final most successfull model has the correct distribution \n",
        "for all problems. Only for this problem.\n",
        "I will check last layer, deciding on final outputs.\n",
        "By looking at images for different epochs,\n",
        "I see when accuracy is high weights are confined into a smaller area.\n",
        "\"\"\"\n",
        "%load_ext tensorboard\n",
        "import tensorflow as tf\n",
        "import datetime, os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1zAO-t9-wvX",
        "colab_type": "code",
        "outputId": "bab6eb83-ba90-405d-c85c-370ea2bfb5cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras import backend as K\n",
        "import keras\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKoWGzcP-zl0",
        "colab_type": "code",
        "outputId": "240d2f87-200f-4ab4-c6de-5525630b86e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        }
      },
      "source": [
        "#code in official document \n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owiEhvE6-1sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#a method for running an architecture for different epohcs\n",
        "\n",
        "from keras import backend as K \n",
        "def train_model(model_name,epoch_train):\n",
        "  K.clear_session()\n",
        "  tf.keras.backend.clear_session\n",
        "  model_cnn = tf.keras.models.Sequential()\n",
        "  model_cnn.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
        "  model_cnn.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model_cnn.add(tf.keras.layers.Flatten())\n",
        "  model_cnn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  model_cnn.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "  model_cnn.compile(loss=keras.losses.categorical_crossentropy,optimizer=tf.keras.optimizers.Adadelta(),metrics=['accuracy'])\n",
        "\n",
        "  logdir = os.path.join(\"logs\"+model_name, datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "  print(\"logdir\",logdir)\n",
        "  tensorboard_callback3 = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "  model_cnn.summary()\n",
        "  model_cnn.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epoch_train,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),callbacks=[tensorboard_callback3])\n",
        "\n",
        "  return logdir"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WhSY0w2-7qO",
        "colab_type": "code",
        "outputId": "f32e6feb-8e92-4614-9224-4bfe0962ac3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 974
        }
      },
      "source": [
        "#run for different epochs and dump their tensorboard and compare results\n",
        "#export of colab notebook does not include images and graphs will cut manually and add\n",
        "train_model(\"4\",4)\n",
        "train_model(\"8\",8)\n",
        "train_model(\"12\",12)\n",
        "train_model(\"16\",16)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:107: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:111: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "logdir logs8/20200319-132914\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5408)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                346176    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 347,146\n",
            "Trainable params: 347,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/8\n",
            "60000/60000 [==============================] - 42s 701us/sample - loss: 2.2874 - acc: 0.1357 - val_loss: 2.2571 - val_acc: 0.2007\n",
            "Epoch 2/8\n",
            "60000/60000 [==============================] - 42s 699us/sample - loss: 2.2245 - acc: 0.2846 - val_loss: 2.1908 - val_acc: 0.3550\n",
            "Epoch 3/8\n",
            "60000/60000 [==============================] - 41s 687us/sample - loss: 2.1564 - acc: 0.4104 - val_loss: 2.1176 - val_acc: 0.4550\n",
            "Epoch 4/8\n",
            "60000/60000 [==============================] - 42s 695us/sample - loss: 2.0776 - acc: 0.5031 - val_loss: 2.0311 - val_acc: 0.5376\n",
            "Epoch 5/8\n",
            "60000/60000 [==============================] - 40s 670us/sample - loss: 1.9903 - acc: 0.5634 - val_loss: 1.9402 - val_acc: 0.5820\n",
            "Epoch 6/8\n",
            "60000/60000 [==============================] - 41s 690us/sample - loss: 1.8981 - acc: 0.6043 - val_loss: 1.8436 - val_acc: 0.6180\n",
            "Epoch 7/8\n",
            "60000/60000 [==============================] - 41s 689us/sample - loss: 1.8007 - acc: 0.6373 - val_loss: 1.7422 - val_acc: 0.6543\n",
            "Epoch 8/8\n",
            "60000/60000 [==============================] - 41s 684us/sample - loss: 1.6987 - acc: 0.6681 - val_loss: 1.6366 - val_acc: 0.6859\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'logs8/20200319-132914'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFaotN-y-8yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorboard --logdir logs8"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTnbeU7WAk_q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}